{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NMF RANK DETERMINATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import linkage, cophenet\n",
    "from tqdm import tqdm\n",
    "from nmf_utils import *\n",
    "\n",
    "# Ignore ConvergenceWarning messages from Scikit-learn\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "DATA_PATH = r'../datasets'\n",
    "\n",
    "DATASET_NAME = r'swimmer_2.csv'          # Swimmer\n",
    "# DATASET_NAME = r'Sausage Raw NIR.csv'  # Sausage\n",
    "# DATASET_NAME = r'ALL-AML Brunet.csv'   # Brunet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df, m0 = read_dataset(DATA_PATH, DATASET_NAME, show_data=False)\n",
    "(n, p) = np.shape(m0)\n",
    "c_w = np.zeros(n)\n",
    "c_h = np.zeros(p)\n",
    "iln1 = np.triu_indices(n, 1)\n",
    "ilp1 = np.triu_indices(p, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_comp = 10  # default=10\n",
    "max_comp = 20  # default=20\n",
    "n_runs = 50    # default=50\n",
    "iter_max = 10  # default=10\n",
    "\n",
    "test_w = np.zeros(max_comp)\n",
    "test_h = np.zeros(max_comp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Workflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "for n_comp in tqdm(range(min_comp, max_comp + 1)):\n",
    "    my_nmfmodel = NMF(n_components=n_comp, init='nndsvda', solver='cd', beta_loss='frobenius', max_iter=iter_max, random_state=0)\n",
    "    w4 = my_nmfmodel.fit_transform(m0)\n",
    "    h4 = my_nmfmodel.components_.T\n",
    "    error = np.linalg.norm(m0 - w4 @ h4.T)\n",
    "    co_w = np.zeros(int(n * (n - 1) / 2))\n",
    "    co_h = np.zeros(int(p * (p - 1) / 2))\n",
    "    my_nmfmodel_random = NMF(n_components=n_comp, init='custom', solver='cd', beta_loss='frobenius', max_iter=iter_max, random_state=0)\n",
    "\n",
    "    for i_run in tqdm(range(0, n_runs)):\n",
    "        # print('n_comp = ' + str(n_comp) + '; i_run = ' + str(i_run))\n",
    "        w4_init = np.random.rand(n, n_comp); h4_init = np.random.rand(p, n_comp).T\n",
    "        w4 = my_nmfmodel_random.fit_transform(m0, W=w4_init, H=h4_init)\n",
    "        h4 = my_nmfmodel_random.components_.T\n",
    "        c_w = np.argmax(normalize(w4, axis=0), axis=1)\n",
    "        c_h = np.argmax(normalize(h4, axis=0), axis=1)\n",
    "        # co_w += np.array([c_w[i] == c_w[j] for i in range(0,n-1) for j in range(i+1,n)])\n",
    "        # co_h += np.array([c_h[i] == c_h[j] for i in range(0,p-1) for j in range(i+1,p)])\n",
    "        co_w += np.equal.outer(c_w, c_w)[iln1]\n",
    "        co_h += np.equal.outer(c_h, c_h)[ilp1]\n",
    "\n",
    "    co_w = 1 - co_w / n_runs\n",
    "    co_h = 1 - co_h / n_runs\n",
    "    \n",
    "    cpc_w, cp_w = cophenet(linkage(co_w, method='ward'), co_w)\n",
    "    cpc_h, cp_h = cophenet(linkage(co_h, method='ward'), co_h)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    test_w[n_comp - 1] = cpc_w / error\n",
    "    test_h[n_comp - 1] = cpc_h / error\n",
    "\n",
    "time_elapsed = (time.time() - time_start)\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cusum Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cusum = cusum_calculation(min_comp, max_comp, test_w, test_h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rank Estimation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimated_rank = rank_estimation(cusum, max_comp)\n",
    "print(estimated_rank)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.savetxt(DATA_PATH + r'\\brunet\\test_scipy_cd_brunet.csv',  np.concatenate((test_w, test_h), axis=0), delimiter=',')\n",
    "# # np.savetxt(DATA_PATH + r'\\sausage\\test_scipy_cd_sausage.csv',  np.concatenate((test_w, test_h), axis=0), delimiter=',')\n",
    "# np.savetxt(DATA_PATH + r'\\swimmer\\test_scipy_cd_swimmer.csv',  np.concatenate((test_w, test_h), axis=0), delimiter=',')\n",
    "# # np.savetxt(DATA_PATH + r'\\esg\\test_scipy_cd_esg.csv',  np.concatenate((test_w, test_h), axis=0), delimiter=',')\n",
    "# np.savetxt(DATA_PATH + r'\\foo.csv', 1 - co_h, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
